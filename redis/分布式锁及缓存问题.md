 	



## 一. Redis实现分布式锁

在服务采用集群方式部署时，例如`synchronized`、`ReetrantLock`这种本地锁，无法在多个服务之间生效，此时就需要分布式锁。

Redis 锁主要利用 Redis 的`setnx`原子命令，伪代码如下。

```java
try{
    // 利用原子操作setnx加锁 
    boolean lock = redisUtil.setnx(key, value);   
    // 
    if(!lock){
        return "get lock fail";
    }
    // TODO 业务逻辑

}finally {
    redisUtil.del(key);
}
```

为了防止执行业务逻辑时出现问题，无法释放锁，需要给key设置过期时间，可以采用`set key value ex|px nx`或者使用LUA脚本。

以上加锁方式可能出现的问题：



### 1. 锁误解除与锁并发

假如线程 A 获取到锁，设置过期时间，开始执行业务逻辑，但是当线程A执行业务逻辑的时间超过了设置锁超时的时间，锁会被自动释放，此时线程 B 就可以获取到锁，此时就出现了锁并发的情况；随后线程 A 执行完业务逻辑，释放锁，但是线程 B 还未执行完，那么就相当于线程A释放了线程B的锁。

**对于锁误解除，可以通过设置唯一标识的 value，在释放时通过判断 value 是否相同，防止释放其他线程的锁。**

```java
String val = UUID.randomUUID().toString();
try{
    boolean lock = redisUtil.setnx(key, val);
    if(!lock){
        System.out.println("set fail");
        return "get lock fail";
    }
    Integer product = Integer.valueOf(redisUtil.get("product"));
    if(product > 0){
        redisUtil.decrement("product");
    }
} finally {
    if(val.equals(redisUtil.get(key))){
        redisUtil.del(key);
    }
}
```

**对于锁并发，可以通过守护线程来延长锁的存活时间。例如 Redisson等第三方框架。**

```java
@Bean
public Redisson redisson(){
    Config config = new Config();
    config.useSingleServer().setAddress("redis://172.16.33.52:6379");
    return (Redisson)Redisson.create(config);
}

RLock lock = redisson.getLock(key);
try {
    lock.lock();
    Integer product = Integer.valueOf(redisUtil.get("product"));
    if(product > 0){
        redisUtil.decrement("product");
    }

} finally {
    lock.unlock();
}
```



### 2.  Redis集群产生的问题

为了保证集群的可用性，通常会采用集群或者主从模式来部署，那么下同样会产生锁并发的问题。

- **master 宕机后，加锁的数据未同步到 slave，然后重新选举，此时另外另外一个线程在新的 master 上加锁成功，就会造成锁并发。**
- **当出现集群脑裂时，同样可能会出现锁并发的问题。**

集群脑裂指因为网络问题，导致节点处于不同的网络分区，无法感知到 master 的存在，此时会重新选举 master，造成集群中出现两个 master，此时不同线程就可以获取到同一把锁。



## 二 RedLock

为了解决 master 重新选举时，数据未及时同步问题，Redis 的作者提出了 RedLock(红锁)的算法，RedLock需要多个 Redis master 节点。其加锁步骤如下：

1. **使用相同的 key 和 value 依次尝试从不同的节点获取锁，在尝试获取锁时，需要设置一个网络连接和响应的超时时间，防止客户端一直等待；**
2. **当从超过半数的节点获取到锁时，且获取锁的时间小于锁失效的时间，那么就成功获取到锁；**
3. **如果获取锁失败，那么需要将所有节点上的锁释放。**



##  三 分布式锁存在的一些问题

对于 RedLock，Martin Kleppmann 认为其依然不安全。

### 1. 长时间GC

因为在 GC 时，会出现 STW，所以有可能会出现下面的情况：

![](..\images\redis\redlock-gc.jpg)



client1 获取到锁并设置了锁超时时间，但是此时出现了 STW，而这个 STW 时间较长，导致释放了锁，而client2 此时就可以获取到锁，当client1 的 GC 结束后，会继续执行业务代码。

对于这个问题，Martin Kleppmann 也提出了解决办法，即为每个写操作加上隔离标志。

客户端1获得锁并且获得**序号为33的令牌**，但随后它进入长时间暂停，直至锁超时过期，客户端2获取锁并且获得**序号为34的令牌**，然后将其写入发送到存储服务。随后，客户端1复活并将其写入发送到存储服务，然而存储服务器记得它**已经处理了具有较高令牌号的写入34**，因此它**拒绝令牌33的请求**。
Redlock算法并没有这种**唯一且递增的fencing token生成机制**，这也意味着Redlock算法不能避免由于客户端阻塞带来的锁过期后的操作问题，因此是不安全的。



### 2. 时钟跳跃

若 Redis 发生时钟跳跃，那么会对锁过期时间造成影响，造成获取到同一把锁。



## 四 Redisson加锁源码



### 1. LUA 脚本

```sh
EVAL script numkeys key [key ...] arg [arg ...]　
# 例子
eval "return {KEYS[1], KEYS[2], ARGV[1], ARGV[2]}" 2 key1 key2 val1 val2
```

其中 script 是一段 Lua 脚本，numkeys 用于指定参数个数，key [key ...] 代表 redis 中的 key，arg [arg ...]为参数。



### 2. Redisson加锁流程

redisson 内部使用了大量的 lua 来保证原子操作。

```java
public void lock() {
    try {
        // 加锁
        lock(-1, null, false);
    } catch (InterruptedException e) {
        throw new IllegalStateException();
    }
}

private void lock(long leaseTime, TimeUnit unit, boolean interruptibly) throws InterruptedException {
    long threadId = Thread.currentThread().getId();
    // 尝试获取锁，null：代表获取到锁，没有获取到锁，返回key的剩余存活时间
    Long ttl = tryAcquire(-1, leaseTime, unit, threadId);
    // lock acquired
    if (ttl == null) {
        return;
    }

    RFuture<RedissonLockEntry> future = subscribe(threadId);
    if (interruptibly) {
        commandExecutor.syncSubscriptionInterrupted(future);
    } else {
        commandExecutor.syncSubscription(future);
    }

    try {
        // 未获取到锁的线程，循环尝试获取
        while (true) {
            ttl = tryAcquire(-1, leaseTime, unit, threadId);
            // lock acquired
            if (ttl == null) {
                break;
            }

            // waiting for message
            if (ttl >= 0) {
                try {
                    future.getNow().getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);
                } catch (InterruptedException e) {
                    if (interruptibly) {
                        throw e;
                    }
                    future.getNow().getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);
                }
            } else {
                if (interruptibly) {
                    future.getNow().getLatch().acquire();
                } else {
                    future.getNow().getLatch().acquireUninterruptibly();
                }
            }
        }
    } finally {
        unsubscribe(future, threadId);
    }
    //        get(lockAsync(leaseTime, unit));
}

/**
* waitTime：等待时间
* leaseTime：锁存活时间，默认30s
* unit： 时间单位
* threadId：线程id
*/
private Long tryAcquire(long waitTime, long leaseTime, TimeUnit unit, long threadId) {
    return get(tryAcquireAsync(waitTime, leaseTime, unit, threadId));
}

private <T> RFuture<Long> tryAcquireAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId) {
    //
    if (leaseTime != -1) {
        return tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG);
    }
    RFuture<Long> ttlRemainingFuture = tryLockInnerAsync(waitTime, internalLockLeaseTime,
                                                         TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);
    ttlRemainingFuture.onComplete((ttlRemaining, e) -> {
        if (e != null) {
            return;
        }

        // lock acquired
        if (ttlRemaining == null) {
            scheduleExpirationRenewal(threadId);
        }
    });
    return ttlRemainingFuture;
}

<T> RFuture<T> tryLockInnerAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand<T> command) {
    internalLockLeaseTime = unit.toMillis(leaseTime);

    // 使用Lua脚本，原子性获取锁，可重入
    return evalWriteAsync(getName(), LongCodec.INSTANCE, command,
                          "if (redis.call('exists', KEYS[1]) == 0) then " +
                          "redis.call('hincrby', KEYS[1], ARGV[2], 1); " +
                          "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                          "return nil; " +
                          "end; " +
                          "if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then " +
                          "redis.call('hincrby', KEYS[1], ARGV[2], 1); " +
                          "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                          "return nil; " +
                          "end; " +
                          "return redis.call('pttl', KEYS[1]);",
                          Collections.singletonList(getName()), internalLockLeaseTime, getLockName(threadId));
}
```



## 五. Redis 过期删除策略和内存淘汰机制

### 1.  过期删除策略

常用的删除策略有两种：

- **惰性删除**：再取 key 的时间检查是否过期，对 CPU 友好，但可能存在大量过期 key 没有被访问而未删除。
- **定时删除**：每隔一段时间删除一批过期 key。

**Redis 中采用的是惰性删除 + 定时删除**。即便是采用两种删除策略，还是有可能会出现漏掉许多过期 key 的情况，导致大量过期 key 存在内存中，出现 Out of memory 的情况。为了解决这种情况，Redis 加入了内存淘汰机制，当使用内存超过设置的 maxmemory 时触发。



### 2. 内存淘汰机制

- **volatile-lru**：从设置过期时间的数据中，删除最近最少使用的 ；
- **volatile-ttl**：从设置过期时间的数据中，删除将要过期的；
- **volatile-random**：从设置过期时间数据中，随机删除；
- **volatile-lfu**：从设置过期时间数据中，删除最少使用的；
- **allkeys-lru**：删除最近最少使用的；
- **allkeys-random**：随机删除；
- **allkeys-lfu**：删除最少使用的；
- **no-eviction**：不删除，报错。



## 六 缓存穿透、雪崩

### 1. 缓存穿透

缓存穿透指查询一个根本不存在的数据，导致大量的请求落在数据库上，解决办法：

**缓存空值**

如果缓存和数据库都查不到数据，将其缓存在 Redis 中，并设置过期时间，这种方法适合请求 key 变化不频繁的情况，对于大量恶意请求，若每次的 key 都不同，会导致 Redis 中缓存大量无效数据。

**布隆过滤器**

对于恶意攻击，请求大量不存在的数据时，可以先用布隆过滤器做一次过滤，当布隆过滤器说**某个值存在时，这个只可能不存在，当某个值不存在时，那么一定不存在。**

布隆过滤器就是一个很大的**位数组，通过几个不一样的 hash 算法，将数据均匀的分布**，想布隆过滤器中添加数据时，会通过多个 hash 算法计算出 hash 值，然后将数组对应位置的置为 1 ，查询的时候用同样的算法，得出索引位置，如果全都为 1 ，那么这个值可能存在，如果有一个索引位置为 0，那么该值肯定不存在。

这种方法适用于数据命中不高、 数据相对固定、 实时性低（通常是数据集较大） 的应用场景， 代码维护较为复杂， 但是**缓存空间占用很少**。

使用布隆过滤器需要提前将数据放入其中，而且布隆过滤器不能删除数据，如果需要删除得重新初始化。



### 2. 缓存雪崩

缓存雪崩是指缓存层支撑板不住，导致大量请求落在存储层，造成存储层级联崩溃，例如大量缓存同时失效的场景。

预防和解决缓存雪崩问题一些办法：

- 保证缓存高可用，比如采用哨兵或集群模式，缓存中的 key 过期时间设置为随机值，防止缓存失效；
- 使用隔离组件为存储层熔断限流降级。



## 七 数据库和缓存的一致性

### 1. 先更新数据库，然后删除缓存

最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，**先更新数据库，然后再删除缓存**。

对于更新缓存代价较高且访问不是特别频繁的场景，可以采用这种方式，例如缓存中存储的是经过复杂业务逻辑得到值，如果采用更新数据库，然后更新缓存的策略，那么在更新操作较为频繁时，会导致频繁的更新缓存，影响性能。

**对于这种策略，如果删除缓存时失败，那么就会造成数据库与缓存不一致，而且这种策略在读请求较多的情况下，还可能会导致大量的请求同时更新缓存。**



### 2. 延时双删

**这种策略是先删除缓存，然后更新数据库，之后再删除缓存。**

这种策略与先更新数据库，再删除缓存相比，缓存不一致的情况只会出现在第一次删除和第二次删除这段时间之间，对于极端的情况，例如第二次删除失败，还是会导致数据库和缓存不一致，或者在第二次删除前，线程 A 先请求数据，缓存中没有，拿到数据库的旧数据，但是删除缓存的线程 B 先于线程 A 执行，然后线程 A 将旧数据写入缓存，造成缓存和数据库不一致。

为了保证第二次删除成功，可以通过消息队列进行重试。为了减少代码的入侵，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。





### 3. 读写请求串行化，保存到内存队列中

**这种策略会导致系统吞吐量大幅度降低，不是严格要求一致性可以不考虑**。

这种策略也是需要先删除缓存，在更新数据时，根据数据的唯一标识将操作发送到 jvm 内部队列，读取数据时，若发现数据不再缓存中，那么将读取数据 + 写入缓存的操作发送到同一个队列中，为了减少相同的写入缓存操作，可以将多个更新操作进行过滤。









## 参考：

https://mp.weixin.qq.com/s/hoZB0wdwXfG3ECKlzjtPdw 

https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/redis-cluster.md